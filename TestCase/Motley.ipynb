{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rtree import index\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "class Motley():\n",
    "    def __init__(self, threshold=0.2, alpha=0.1, idx_method=\"rtree\"):\n",
    "        self.threshold = threshold\n",
    "        self.alpha = alpha\n",
    "        self.idx_method = idx_method if idx_method == \"kdtree\" else \"rtree\"\n",
    "    \n",
    "    # X means data point in the spatial space\n",
    "    # Z means corresponding attribute representation\n",
    "    def datafeed(self, X, Z):\n",
    "        # rownum: number of points, colnum: spatial dimension\n",
    "        rownum, colnum = X.shape\n",
    "        \n",
    "        if(rownum != Z.shape[0]):\n",
    "            print(\"Number of input data doesn't match\")\n",
    "            return\n",
    "        \n",
    "        self.attributeset = Z\n",
    "        num_attrs = self.attributeset.shape[1]\n",
    "        a = self.alpha\n",
    "        \n",
    "        # Build up index (kd-tree / R-tree)\n",
    "        if self.idx_method == \"kdtree\":\n",
    "            # Note: kd-tree doesn't support additional object linkage\n",
    "            self.index = KDTree(X)\n",
    "        else:\n",
    "            p = index.Property()\n",
    "            p.dimension = colnum\n",
    "            self.index = index.Index(properties=p)\n",
    "            for idx, row in enumerate(X):\n",
    "                # (1) Index based on row number\n",
    "                # (2) Store point for the bounding box\n",
    "                # (3) Store attribute representation as inner object\n",
    "                self.index.insert(idx, np.append(row, row), Z[idx])\n",
    "                \n",
    "        # Weights used for computing MinDiv\n",
    "        # Number of weights depends on dimension of attribute space.\n",
    "        self.weight = np.fromfunction(\n",
    "            lambda self, x: ((a**(x))*(1-a)/(1-a**num_attrs))\n",
    "            , (1, num_attrs))\n",
    "    \n",
    "    # Query a point and find its diversed neighbors\n",
    "    # aggress is set for next round's search, if k neighbors are not found\n",
    "    # max_iter is set to avoid whole-document scanning\n",
    "    def search(self, qs_space, k=10, aggress=5, approach=\"greedy\", max_iter=5):\n",
    "        # Initial search: nearest (k * aggress) points\n",
    "        s_amount = k*aggress\n",
    "        filtered, num_iter = 0, 0 # Neighbors found / Iteration already run\n",
    "        \n",
    "        # Initial result contains zero row, so the nearest neighbor is guaranteed\n",
    "        # to be in the result set.\n",
    "        res = np.empty((0, self.attributeset.shape[1]))\n",
    "        ret = []\n",
    "        \n",
    "        if self.idx_method == \"kdtree\":\n",
    "            # TODO: should stop if s_amount > size of dataset\n",
    "            while (len(res) != k) or (num_iter < max_iter):\n",
    "                # [filtered:] - Exclude those already exaimed\n",
    "                q_ans = self.index.query(qs_space, k=s_amount, return_distance=False)[filtered:]\n",
    "                # the query returns a list of indices, get point attributes from self.attrs\n",
    "                for cand in q_ans:\n",
    "                    # Add if pass the diversity test\n",
    "                    if self.diversity_check_greedy(res, self.attributeset[cand]):\n",
    "                        ret.append(cand)\n",
    "                        res = np.vstack([res, cand])\n",
    "                    \n",
    "                    filtered += 1\n",
    "                    \n",
    "                    if len(res) == k:\n",
    "                        break\n",
    "                # Start the next round\n",
    "                if len(res) != k:\n",
    "                    num_iter += 1\n",
    "                    s_amount *= aggress\n",
    "        else:\n",
    "            while len(res) != k and (num_iter < max_iter):\n",
    "                print(\"round %d...\" % num_iter)\n",
    "                print(\"search size = %d\" % s_amount)\n",
    "                q_ans = self.index.nearest(np.append(qs_space, qs_space), s_amount, objects=True)\n",
    "                for cand in q_ans:\n",
    "                    tmp_attr = cand.object\n",
    "                    if self.diversity_check_greedy(res, tmp_attr):\n",
    "                        ret.append(cand.id)\n",
    "                        res = np.vstack([res, tmp_attr])\n",
    "                    filtered += 1\n",
    "                    if len(res) == k:\n",
    "                        break\n",
    "                        \n",
    "                if len(res) != k:\n",
    "                    num_iter += 1\n",
    "                    s_amount *= aggress\n",
    "        return ret\n",
    "    \n",
    "    def diversity_check_greedy(self, X, q):\n",
    "        size_data, _ = X.shape\n",
    "\n",
    "        for i in range(size_data):\n",
    "            # Sort 1-D difference (In ascending order)\n",
    "            diff_sorted = np.sort(np.absolute(X[i] - q))\n",
    "            # Weighting\n",
    "            divdist_tmp = diff_sorted * self.weight\n",
    "            # If difference is too small, dispose it\n",
    "            if divdist_tmp.sum() <= self.threshold:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 55)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "max_line = 4000\n",
    "dataset_path = \"./../dataset/Forest_Cover/covtype.data\"\n",
    "dataset_w_path = \"./../dataset/Forest_Cover/covtype_s.data\"\n",
    "fd = open(dataset_path)\n",
    "fd_w = open(dataset_w_path, \"w\")\n",
    "ct = 0\n",
    "for line in fd.readlines():\n",
    "    fd_w.write(line + '\\n')\n",
    "    ct += 1\n",
    "    if ct >= max_line:\n",
    "        break\n",
    "        \n",
    "fd.close()\n",
    "fd_w.close()\n",
    "'''\n",
    "dataset_path = \"./../dataset/Forest_Cover/covtype.data\"\n",
    "r = np.genfromtxt(dataset_path, delimiter=',', dtype=None, names=None)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581012, 2)\n",
      "(581012, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "data_space = minmax_scale(r[::, (0, 1)], copy=False)\n",
    "data_attributes = minmax_scale(r[::, (2, 3, 4)], copy=False)\n",
    "\n",
    "print(data_space.shape)\n",
    "print(data_attributes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query no. 1\n",
      "round 0...\n",
      "search size = 50\n",
      "round 1...\n",
      "search size = 250\n",
      "round 2...\n",
      "search size = 1250\n",
      "round 3...\n",
      "search size = 6250\n",
      "round 4...\n",
      "search size = 31250\n",
      "Query no. 2\n",
      "round 0...\n",
      "search size = 50\n",
      "round 1...\n",
      "search size = 250\n",
      "round 2...\n",
      "search size = 1250\n",
      "round 3...\n",
      "search size = 6250\n",
      "round 4...\n",
      "search size = 31250\n",
      "Query no. 3\n",
      "round 0...\n",
      "search size = 50\n",
      "round 1...\n",
      "search size = 250\n",
      "round 2...\n",
      "search size = 1250\n",
      "round 3...\n",
      "search size = 6250\n",
      "round 4...\n",
      "search size = 31250\n",
      "Query no. 4\n",
      "round 0...\n",
      "search size = 50\n",
      "round 1...\n",
      "search size = 250\n",
      "round 2...\n",
      "search size = 1250\n",
      "round 3...\n",
      "search size = 6250\n",
      "Query no. 5\n",
      "round 0...\n",
      "search size = 50\n",
      "round 1...\n",
      "search size = 250\n",
      "round 2...\n",
      "search size = 1250\n",
      "round 3...\n",
      "search size = 6250\n",
      "round 4...\n",
      "search size = 31250\n",
      "Query no. 6\n",
      "round 0...\n",
      "search size = 50\n",
      "round 1...\n",
      "search size = 250\n",
      "round 2...\n",
      "search size = 1250\n",
      "round 3...\n",
      "search size = 6250\n",
      "Query no. 7\n",
      "round 0...\n",
      "search size = 50\n",
      "round 1...\n",
      "search size = 250\n",
      "round 2...\n",
      "search size = 1250\n",
      "Query no. 8\n",
      "round 0...\n",
      "search size = 50\n",
      "round 1...\n",
      "search size = 250\n",
      "round 2...\n",
      "search size = 1250\n",
      "round 3...\n",
      "search size = 6250\n",
      "round 4...\n",
      "search size = 31250\n",
      "Query no. 9\n",
      "round 0...\n",
      "search size = 50\n",
      "round 1...\n",
      "search size = 250\n",
      "round 2...\n",
      "search size = 1250\n",
      "round 3...\n",
      "search size = 6250\n",
      "Query no. 10\n",
      "round 0...\n",
      "search size = 50\n",
      "round 1...\n",
      "search size = 250\n",
      "round 2...\n",
      "search size = 1250\n",
      "round 3...\n",
      "search size = 6250\n",
      "round 4...\n",
      "search size = 31250\n"
     ]
    }
   ],
   "source": [
    "finder = Motley()\n",
    "finder.datafeed(data_space, data_attributes)\n",
    "\n",
    "space1_max, space1_min, space2_max, space2_min = data_space[::, 0].max(), data_space[::, 0].min(), data_space[::, 1].max(), data_space[::, 1].min()\n",
    "\n",
    "rand1 = np.random.uniform(space1_min, space1_max, size=(10, 1))\n",
    "rand2 = np.random.uniform(space2_min, space2_max, size=(10, 1))\n",
    "\n",
    "test_input_space = np.hstack([rand1, rand2])\n",
    "\n",
    "res = []\n",
    "\n",
    "finder.threshold = 0.05\n",
    "\n",
    "for i, q in enumerate(test_input_space):\n",
    "    print(\"Query no. %d\" % (i+1))\n",
    "    res.append(finder.search(q))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[251136, 1858, 4559, 246076, 225809, 247214, 279473, 579790, 110606],\n",
       " [239279, 239281, 244563, 267792, 259526, 263571, 276645],\n",
       " [460095,\n",
       "  313101,\n",
       "  407305,\n",
       "  385480,\n",
       "  525770,\n",
       "  447558,\n",
       "  526721,\n",
       "  510450,\n",
       "  552436,\n",
       "  254503],\n",
       " [519081,\n",
       "  374664,\n",
       "  339086,\n",
       "  409662,\n",
       "  310678,\n",
       "  229346,\n",
       "  432456,\n",
       "  550774,\n",
       "  334913,\n",
       "  224569],\n",
       " [25999, 319241, 179854, 109389, 448819, 390227, 353833, 203226, 369870],\n",
       " [198869,\n",
       "  242597,\n",
       "  255700,\n",
       "  301859,\n",
       "  550555,\n",
       "  555207,\n",
       "  518452,\n",
       "  437298,\n",
       "  553451,\n",
       "  376913],\n",
       " [346552,\n",
       "  353735,\n",
       "  10557,\n",
       "  538425,\n",
       "  351281,\n",
       "  495802,\n",
       "  454615,\n",
       "  359838,\n",
       "  528076,\n",
       "  345960],\n",
       " [227214, 2651, 222161, 229634, 253784, 255465, 223924, 262116],\n",
       " [101509,\n",
       "  224574,\n",
       "  156331,\n",
       "  136193,\n",
       "  370152,\n",
       "  404178,\n",
       "  364644,\n",
       "  345490,\n",
       "  458939,\n",
       "  228855],\n",
       " [252118,\n",
       "  259296,\n",
       "  132844,\n",
       "  234377,\n",
       "  228373,\n",
       "  226451,\n",
       "  226660,\n",
       "  551537,\n",
       "  315978,\n",
       "  227899]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# q_space: query in spatial space, S: returned neighbors\n",
    "# -space: spatial vector; -attr: attribute vector\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "def evaluation(q_space, S_space, S_attr, metric_s=\"euclidean\", metric_a=\"cosine\"):\n",
    "    # max_dist\n",
    "    q_dists = cdist([q], S_space, metric=metric_s)\n",
    "    avg_query_dist = q_dists.mean()\n",
    "    max_dist = q_dists.max()\n",
    "    p_dists = pdist(S_attr, metric=metric_a)\n",
    "    avg_pairwise_dist = p_dists.mean()\n",
    "    # Farthest point from query in spatial space / Average distance in spatial space\n",
    "    # / Average pairwise distance between answers in attribute space\n",
    "    return max_dist, avg_query_dist, avg_pairwise_dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.83857904430967178, 0.77896951942482262, 0.20255558853420152)\n",
      "(0.42237510968985326, 0.3276089746780303, 0.12979665021814057)\n",
      "(0.53914274591865718, 0.51970187161901893, 0.1352733505990826)\n",
      "(0.18881631495590698, 0.16942592715348861, 0.1381368811209859)\n",
      "(0.65288686295357334, 0.63767005032083612, 0.16755783066269447)\n",
      "(0.52226304758730835, 0.50929478442014853, 0.20013262433845821)\n",
      "(0.73753568476491416, 0.63149652254518496, 0.1209804159022561)\n",
      "(0.35561843814660282, 0.31763989385951297, 0.16572554029467021)\n",
      "(0.14697673742588793, 0.135831519691541, 0.14029775070142672)\n",
      "(0.097504919707735851, 0.032297405504245404, 0.085547496563976866)\n"
     ]
    }
   ],
   "source": [
    "for idx, ans in enumerate(res):\n",
    "    print(evaluation(test_input_space[idx], data_space[ans], data_attributes[ans]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
